{'baseline_xy': '/root/disk/scratch/model-tmnmt/baseline_fren.npz',
 'baseline_yx': '/root/disk/scratch/model-tmnmt/baseline_enfr.bs64.npz',
 'batch_size': 32,
 'beamsize': 5,
 'build_gate': True,
 'clip_c': 1.0,
 'd_maxlen': 200,
 'datasets': ['/root/workspace/TMNMT/.dataset/tm2.fren/train.fr.top5.shuf.tok',
              '/root/workspace/TMNMT/.dataset/tm2.fren/train.en.top5.shuf.tok',
              '/root/workspace/TMNMT/.dataset/tm2.fren/train.fr.top5.matched.shuf.tok',
              '/root/workspace/TMNMT/.dataset/tm2.fren/train.en.top5.matched.shuf.tok'],
 'decay_c': 0.0,
 'decoder': 'gru_cond',
 'dictionaries': ['/root/workspace/TMNMT/.dataset/tm2.fren/train.fr.top5.shuf.tok.pkl',
                  '/root/workspace/TMNMT/.dataset/tm2.fren/train.en.top5.shuf.tok.pkl',
                  '/root/workspace/TMNMT/.dataset/tm2.fren/train.fr.top5.shuf.tok.pkl',
                  '/root/workspace/TMNMT/.dataset/tm2.fren/train.en.top5.shuf.tok.pkl'],
 'dim': 1024,
 'dim_word': 512,
 'dispFreq': 10,
 'encoder': 'gru',
 'gate_lambda': 0.1,
 'gate_loss': True,
 'lrate': 0.0001,
 'maxlen': 50,
 'normalize': True,
 'only_train_g': True,
 'optimizer': 'adam',
 'overwrite': True,
 'patience': 1000,
 'reload_': True,
 'sampleFreq': 20,
 'saveFreq': 500,
 'saveto': '/root/disk/scratch/model-tmnmt/TM2.v5_fren.ff.32-50.npz',
 'stochastic': False,
 'tm_source': '/root/workspace/TMNMT/.dataset/tm2.fren/devset.fr.matched.tok',
 'tm_target': '/root/workspace/TMNMT/.dataset/tm2.fren/devset.en.matched.tok',
 'trans_from': '/root/workspace/TMNMT/.dataset/tm2.fren/devset.fr.tok',
 'trans_ref': '/root/workspace/TMNMT/.dataset/tm2.fren/devset.en.tok',
 'trans_to': '/root/workspace/TMNMT/.translate/TM2.v1.translate',
 'use_coverage': False,
 'use_dropout': False,
 'use_pretrain': True,
 'validFreq': 100,
 'valid_batch_size': 32,
 'valid_datasets': ['/root/workspace/TMNMT/.dataset/tm2.fren/devset.fr.tok',
                    '/root/workspace/TMNMT/.dataset/tm2.fren/devset.en.tok',
                    '/root/workspace/TMNMT/.dataset/tm2.fren/devset.fr.matched.tok',
                    '/root/workspace/TMNMT/.dataset/tm2.fren/devset.en.matched.tok'],
 'voc_sizes': [20000, 20000, 20000, 20000]}
Building model: X -> Y & Y -> X model
Done.
load the pretrained NMT-models... load ... xy_Wemb
load ... xy_Wemb_dec
load ... xy_encoder_W
load ... xy_encoder_b
load ... xy_encoder_U
load ... xy_encoder_Wx
load ... xy_encoder_bx
load ... xy_encoder_Ux
load ... xy_encoder_r_W
load ... xy_encoder_r_b
load ... xy_encoder_r_U
load ... xy_encoder_r_Wx
load ... xy_encoder_r_bx
load ... xy_encoder_r_Ux
load ... xy_ff_state_W
load ... xy_ff_state_b
load ... xy_decoder_W
load ... xy_decoder_b
load ... xy_decoder_U
load ... xy_decoder_Wx
load ... xy_decoder_Ux
load ... xy_decoder_bx
load ... xy_decoder_U_nl
load ... xy_decoder_b_nl
load ... xy_decoder_Ux_nl
load ... xy_decoder_bx_nl
load ... xy_decoder_Wc
load ... xy_decoder_Wcx
load ... xy_decoder_W_comb_att
load ... xy_decoder_Wc_att
load ... xy_decoder_b_att
load ... xy_decoder_U_att
load ... xy_decoder_c_tt
load ... xy_ff_logit_lstm_W
load ... xy_ff_logit_lstm_b
load ... xy_ff_logit_prev_W
load ... xy_ff_logit_prev_b
load ... xy_ff_logit_ctx_W
load ... xy_ff_logit_ctx_b
load ... xy_ff_logit_W
load ... xy_ff_logit_b
Done.
build forward-attention models (2 models simultaneously)...
Build f_critic... Done
build mapping (bi-linear model)!
Building Mapping functions, ... Done.
build loss function (w/o gate)
build sampler (one-step)
Building f_init... Done
Building f_next... Done
build old sampler
Building f_init... Done
Building f_next... Done
build Cost Function... build Gradient (backward)... Done
Building Optimizers... Done
Build Networks... done!
build_networks: elapsed 272.0461 secs.
Loading data
[33m-------------------------------------------- Main-Loop -------------------------------------------------[0m
[31mdimension mismatch in args to gemm (1568,4096)x(5120,2)->(1568,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(1568, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (1312,4096)x(5120,2)->(1312,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(1312, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (1184,4096)x(5120,2)->(1184,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(1184, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (1088,4096)x(5120,2)->(1088,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(1088, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (992,4096)x(5120,2)->(992,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(992, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (864,4096)x(5120,2)->(864,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(864, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (768,4096)x(5120,2)->(768,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(768, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (672,4096)x(5120,2)->(672,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(672, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (576,4096)x(5120,2)->(576,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(576, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (512,4096)x(5120,2)->(512,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(512, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (448,4096)x(5120,2)->(448,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(448, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (384,4096)x(5120,2)->(384,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(384, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (320,4096)x(5120,2)->(320,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(320, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (288,4096)x(5120,2)->(288,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(288, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (224,4096)x(5120,2)->(224,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(224, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (1632,4096)x(5120,2)->(1632,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(1632, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (1408,4096)x(5120,2)->(1408,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(1408, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (1216,4096)x(5120,2)->(1216,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(1216, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
[31mdimension mismatch in args to gemm (1120,4096)x(5120,2)->(1120,2)
Apply node that caused the error: GpuDot22(GpuReshape{2}.0, GpuReshape{2}.0)
Toposort index: 837
Inputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]
Inputs shapes: [(1120, 4096), (5120, 2)]
Inputs strides: [(4096, 1), (2, 1)]
Inputs values: ['not shown', 'not shown']
Outputs clients: [[GpuReshape{3}(GpuDot22.0, MakeVector{dtype='int64'}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.[0m
