{'baseline_xy': '/root/disk/scratch/model-tmnmt/baseline_fren.npz',
 'baseline_yx': '/root/disk/scratch/model-tmnmt/baseline_enfr.bs64.npz',
 'batch_size': 32,
 'beamsize': 5,
 'bleuFreq': 5000,
 'build_gate': True,
 'check_bleu': True,
 'clip_c': 1.0,
 'cov_dim': 10,
 'd_maxlen': 200,
 'datasets': ['/root/workspace/TMNMT/.dataset/tm2.fren/train.fr.top5.shuf.tok',
              '/root/workspace/TMNMT/.dataset/tm2.fren/train.en.top5.shuf.tok',
              '/root/workspace/TMNMT/.dataset/tm2.fren/train.fr.top5.matched.shuf.tok',
              '/root/workspace/TMNMT/.dataset/tm2.fren/train.en.top5.matched.shuf.tok'],
 'decay_c': 0.0,
 'decoder': 'gru_cond',
 'diagonal': True,
 'dictionaries': ['/root/workspace/TMNMT/.dataset/tm2.fren/train.fr.top5.shuf.tok.pkl',
                  '/root/workspace/TMNMT/.dataset/tm2.fren/train.en.top5.shuf.tok.pkl',
                  '/root/workspace/TMNMT/.dataset/tm2.fren/train.fr.top5.shuf.tok.pkl',
                  '/root/workspace/TMNMT/.dataset/tm2.fren/train.en.top5.shuf.tok.pkl'],
 'dim': 1024,
 'dim_word': 512,
 'encoder': 'gru',
 'gate_lambda': 0.1,
 'gate_loss': False,
 'lrate': 0.0001,
 'maxlen': 50,
 'name': 'TM2.basic.v1',
 'nn_coverage': False,
 'normalize': True,
 'only_train_g': False,
 'optimizer': 'adam',
 'overwrite': False,
 'patience': 1000,
 'reload_': True,
 'sampleFreq': 20,
 'saveFreq': 250,
 'saveto': '/root/disk/scratch/model-tmnmt/TM2.basic.v1_fren.ss.32-50.npz',
 'stochastic': False,
 'tm_source': '/root/workspace/TMNMT/.dataset/tm2.fren/devset.fr.matched.tok',
 'tm_target': '/root/workspace/TMNMT/.dataset/tm2.fren/devset.en.matched.tok',
 'trans_from': '/root/workspace/TMNMT/.dataset/tm2.fren/devset.fr.tok',
 'trans_ref': '/root/workspace/TMNMT/.dataset/tm2.fren/devset.en.tok',
 'trans_to': '/root/workspace/TMNMT/.translate/TM2.basic.v1.translate',
 'use_coverage': True,
 'use_dropout': False,
 'use_pretrain': False,
 'validFreq': 250,
 'valid_batch_size': 32,
 'valid_datasets': ['/root/workspace/TMNMT/.dataset/tm2.fren/devset.fr.tok',
                    '/root/workspace/TMNMT/.dataset/tm2.fren/devset.en.tok',
                    '/root/workspace/TMNMT/.dataset/tm2.fren/devset.fr.matched.tok',
                    '/root/workspace/TMNMT/.dataset/tm2.fren/devset.en.matched.tok'],
 'voc_sizes': [20000, 20000, 20000, 20000]}
Building model: X -> Y & Y -> X model
Done.
load the pretrained NMT-models... load ... xy_Wemb
load ... xy_Wemb_dec
load ... xy_encoder_W
load ... xy_encoder_b
load ... xy_encoder_U
load ... xy_encoder_Wx
load ... xy_encoder_bx
load ... xy_encoder_Ux
load ... xy_encoder_r_W
load ... xy_encoder_r_b
load ... xy_encoder_r_U
load ... xy_encoder_r_Wx
load ... xy_encoder_r_bx
load ... xy_encoder_r_Ux
load ... xy_ff_state_W
load ... xy_ff_state_b
load ... xy_decoder_W
load ... xy_decoder_b
load ... xy_decoder_U
load ... xy_decoder_Wx
load ... xy_decoder_Ux
load ... xy_decoder_bx
load ... xy_decoder_U_nl
load ... xy_decoder_b_nl
load ... xy_decoder_Ux_nl
load ... xy_decoder_bx_nl
load ... xy_decoder_Wc
load ... xy_decoder_Wcx
load ... xy_decoder_W_comb_att
load ... xy_decoder_Wc_att
load ... xy_decoder_b_att
load ... xy_decoder_U_att
load ... xy_decoder_c_tt
load ... xy_ff_logit_lstm_W
load ... xy_ff_logit_lstm_b
load ... xy_ff_logit_prev_W
load ... xy_ff_logit_prev_b
load ... xy_ff_logit_ctx_W
load ... xy_ff_logit_ctx_b
load ... xy_ff_logit_W
load ... xy_ff_logit_b
Done.
Start a new model
build forward-attention models (2 models simultaneously)...
Build f_critic... Done
build mapping (bi-linear model)!
use linguistic coverage
Building Mapping functions, ... Done.
build loss function (w/o gate)
build sampler (one-step)
Building f_init... Done
Building f_next... Done
build old sampler
Building f_init... Done
Building f_next... Done
build Cost Function... build Gradient (backward)... Done
Building Optimizers... Done
Build Networks... done!
build_networks: elapsed 322.6820 secs.
Loading data
[33m-------------------------------------------- Main-Loop -------------------------------------------------[0m
Epoch  0 Update  0 Cost  309.374176025 G 30.7368812561 execute: elapsed 1.5425 secs.
Open a new thread to compute the BLEU score...
Saving the best model... [test] I am Thread: Thread-1.
Translating  /root/workspace/TMNMT/.dataset/tm2.fren/devset.fr.tok ...to... /root/workspace/TMNMT/.translate/TM2.basic.v1.translate.iter=0
complete translation:1, 12.8953402042s
Done
Saving the model at iteration 0... Done
