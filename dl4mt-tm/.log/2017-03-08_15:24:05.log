{'baseline_xy': '/root/disk/scratch/model-tmnmt/baseline_fren.npz',
 'baseline_yx': '/root/disk/scratch/model-tmnmt/baseline_enfr.bs64.npz',
 'batch_size': 16,
 'beamsize': 5,
 'build_gate': True,
 'clip_c': 1.0,
 'd_maxlen': 200,
 'datasets': ['/root/workspace/TMNMT/.dataset/tm.fren/train.fr.top5.random5.shuf.tok',
              '/root/workspace/TMNMT/.dataset/tm.fren/train.en.top5.random5.shuf.tok',
              '/root/workspace/TMNMT/.dataset/tm.fren/train.fr.top5.random5.matched.shuf.tok',
              '/root/workspace/TMNMT/.dataset/tm.fren/train.en.top5.random5.matched.shuf.tok'],
 'decay_c': 0.0,
 'decoder': 'gru_cond',
 'dictionaries': ['/root/workspace/TMNMT/.dataset/tm.fren/train.fr.top5.random5.shuf.tok.pkl',
                  '/root/workspace/TMNMT/.dataset/tm.fren/train.en.top5.random5.shuf.tok.pkl',
                  '/root/workspace/TMNMT/.dataset/tm.fren/train.fr.top5.random5.shuf.tok.pkl',
                  '/root/workspace/TMNMT/.dataset/tm.fren/train.en.top5.random5.shuf.tok.pkl'],
 'dim': 1024,
 'dim_word': 512,
 'dispFreq': 10,
 'encoder': 'gru',
 'gate_lambda': 0.1,
 'gate_loss': True,
 'lrate': 2e-06,
 'maxlen': 50,
 'normalize': False,
 'optimizer': 'adam',
 'overwrite': True,
 'patience': 1000,
 'reload_': True,
 'sampleFreq': 20,
 'saveFreq': 500,
 'saveto': '/root/disk/scratch/model-tmnmt/new.L-gate.v1_fren.ff.16-50.npz',
 'stochastic': False,
 'trans_from': '/root/workspace/TMNMT/.dataset/fren/devset.fr.tok',
 'trans_ref': '/root/workspace/TMNMT/.dataset/fren/devset.en.tok',
 'trans_to': '/root/workspace/TMNMT/.translate/tmv3_',
 'use_dropout': False,
 'use_pretrain': True,
 'validFreq': 100,
 'valid_batch_size': 32,
 'valid_datasets': ['/root/workspace/TMNMT/.dataset/tm.fren/devset.fr.tok',
                    '/root/workspace/TMNMT/.dataset/tm.fren/devset.en.tok',
                    '/root/workspace/TMNMT/.dataset/tm.fren/devset.fr.matched.tok',
                    '/root/workspace/TMNMT/.dataset/tm.fren/devset.en.matched.tok'],
 'voc_sizes': [20000, 20000, 20000, 20000]}
Building model: X -> Y & Y -> X model
Done.
load the pretrained NMT-models... load ... xy_Wemb
load ... xy_Wemb_dec
load ... xy_encoder_W
load ... xy_encoder_b
load ... xy_encoder_U
load ... xy_encoder_Wx
load ... xy_encoder_bx
load ... xy_encoder_Ux
load ... xy_encoder_r_W
load ... xy_encoder_r_b
load ... xy_encoder_r_U
load ... xy_encoder_r_Wx
load ... xy_encoder_r_bx
load ... xy_encoder_r_Ux
load ... xy_ff_state_W
load ... xy_ff_state_b
load ... xy_decoder_W
load ... xy_decoder_b
load ... xy_decoder_U
load ... xy_decoder_Wx
load ... xy_decoder_Ux
load ... xy_decoder_bx
load ... xy_decoder_U_nl
load ... xy_decoder_b_nl
load ... xy_decoder_Ux_nl
load ... xy_decoder_bx_nl
load ... xy_decoder_Wc
load ... xy_decoder_Wcx
load ... xy_decoder_W_comb_att
load ... xy_decoder_Wc_att
load ... xy_decoder_b_att
load ... xy_decoder_U_att
load ... xy_decoder_c_tt
load ... xy_ff_logit_lstm_W
load ... xy_ff_logit_lstm_b
load ... xy_ff_logit_prev_W
load ... xy_ff_logit_prev_b
load ... xy_ff_logit_ctx_W
load ... xy_ff_logit_ctx_b
load ... xy_ff_logit_W
load ... xy_ff_logit_b
load ... yx_Wemb
load ... yx_Wemb_dec
load ... yx_encoder_W
load ... yx_encoder_b
load ... yx_encoder_U
load ... yx_encoder_Wx
load ... yx_encoder_bx
load ... yx_encoder_Ux
load ... yx_encoder_r_W
load ... yx_encoder_r_b
load ... yx_encoder_r_U
load ... yx_encoder_r_Wx
load ... yx_encoder_r_bx
load ... yx_encoder_r_Ux
load ... yx_ff_state_W
load ... yx_ff_state_b
load ... yx_decoder_W
load ... yx_decoder_b
load ... yx_decoder_U
load ... yx_decoder_Wx
load ... yx_decoder_Ux
load ... yx_decoder_bx
load ... yx_decoder_U_nl
load ... yx_decoder_b_nl
load ... yx_decoder_Ux_nl
load ... yx_decoder_bx_nl
load ... yx_decoder_Wc
load ... yx_decoder_Wcx
load ... yx_decoder_W_comb_att
load ... yx_decoder_Wc_att
load ... yx_decoder_b_att
load ... yx_decoder_U_att
load ... yx_decoder_c_tt
load ... yx_ff_logit_lstm_W
load ... yx_ff_logit_lstm_b
load ... yx_ff_logit_prev_W
load ... yx_ff_logit_prev_b
load ... yx_ff_logit_ctx_W
load ... yx_ff_logit_ctx_b
load ... yx_ff_logit_W
load ... yx_ff_logit_b
Done.
Reloading model parameters
build forward-attention models (4 models simultaneously)...
Build f_critic... Done
Build f_critic... Done
build cross-attention models
build attentions (forward, cross-propagation)
build gates!
Building Gate functions, ... Done.
build loss function (w/o gate)
build sampler (one-step)
Building f_init... Done
Building f_next... Done
Building f_init... Done
Building f_next... Done
build old sampler
Building f_init... Done
Building f_next... Done
Building f_init... Done
Building f_next... Done
build attender (one-step)
Build f_attend... Done.
Build f_attend... Done.
build Cost Function... build Gradient (backward)... Done
Building Optimizers... Done
Build Networks... done!
build_networks: elapsed 915.8564 secs.

Loading data
[33m-------------------------------------------- Main-Loop -------------------------------------------------[0m
Epoch  0 Update  59001 Cost  489.657623291 G 124.362701416
execute: elapsed 6.8581 secs.

Epoch  0 Update  59002 Cost  307.415039062 G 106.93309021
execute: elapsed 6.0375 secs.

Epoch  0 Update  59003 Cost  314.86328125 G 91.0330047607
execute: elapsed 5.3839 secs.

Epoch  0 Update  59004 Cost  324.274505615 G 83.8595657349
execute: elapsed 5.5107 secs.

Epoch  0 Update  59005 Cost  346.103759766 G 81.8956756592
execute: elapsed 5.7186 secs.

Epoch  0 Update  59006 Cost  284.844543457 G 70.7149810791
execute: elapsed 5.4627 secs.

Epoch  0 Update  59007 Cost  247.695114136 G 66.9694366455
execute: elapsed 5.0496 secs.

Epoch  0 Update  59008 Cost  224.096160889 G 58.1614227295
execute: elapsed 4.6889 secs.

Epoch  0 Update  59009 Cost  130.029769897 G 47.7032623291
execute: elapsed 3.5591 secs.

Epoch  0 Update  59010 Cost  127.053161621 G 38.5213165283
execute: elapsed 2.8912 secs.

Epoch  0 Update  59011 Cost  151.11177063 G 40.071434021
execute: elapsed 4.4768 secs.

Epoch  0 Update  59012 Cost  211.32208252 G 46.9919967651
execute: elapsed 4.6343 secs.

Epoch  0 Update  59013 Cost  125.726715088 G 31.4165287018
execute: elapsed 3.7709 secs.

Epoch  0 Update  59014 Cost  188.737533569 G 49.2977523804
execute: elapsed 6.8794 secs.

Epoch  0 Update  59015 Cost  522.099487305 G 112.282546997
execute: elapsed 6.3430 secs.

Epoch  0 Update  59016 Cost  412.268096924 G 105.690734863
execute: elapsed 5.9758 secs.

Epoch  0 Update  59017 Cost  470.833953857 G 102.060844421
execute: elapsed 6.5179 secs.

Epoch  0 Update  59018 Cost  343.18963623 G 81.5021286011
execute: elapsed 5.6816 secs.

Epoch  0 Update  59019 Cost  342.684143066 G 72.5683898926
execute: elapsed 5.1064 secs.

Epoch  0 Update  59020 Cost  253.914169312 G 69.25025177
execute: elapsed 4.9846 secs.

=============================
Target-TM 0: The European Commission hereby presents to the budgetary authority the amending letter No 3 to the preliminary draft budget for 2006 for the reasons set out in the explanatory memorandum .
Source-TM 0: La Commission europ√©enne pr√©sente ci-apr√®s √† l &apos; autorit√© budg√©taire la lettre rectificative n ¬∞ 3 √† l &apos; avant-projet de budget 2006 pour les raisons reprises dans l &apos; expos√© des motifs .
Source-CR 0: 1 . Chaque √âtat membre √©tablit un r√©seau rural national qui regroupe les organisations et les administrations travaillant dans le domaine du d√©veloppement rural .
Target-CR 0: 1 . Each Member State shall establish a national rural network , which groups the organisations and administrations involved in rural development .
-----------------------------
NMT Model 0: 1 . The Member European Member State shall establish to the authority budgetary authority which letter 3 preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary preliminary for rural development reasons
[19, 6, 21, 34, 46, 34, 68, 16, 622, 7, 2, 954, 158, 2, 1191, 10, 1191, 12, 602, 12, 1507, 219, 602, 6, 0]
[[1.0, 0.99985504, 0.033030141, 1.0, 5.2451054e-05, 1.0, 1.0, 1.0, 1.0, 0.0092287501, 2.6246784e-05, 0.00014262213, 0.00044316897, 2.5764673e-05, 1.3793205e-07, 1.0, 7.0436954e-06, 0.011456132, 0.00051026879, 0.00076399726, 1.0, 1.0, 0.0001764773, 0.43287972, 1.0], [1.0, 0.99985504, 0.033030141, 1.0, 5.2451054e-05, 1.0, 1.0, 1.0, 1.0, 0.0092287501, 2.6246784e-05, 0.00014262213, 0.00044316897, 2.5764673e-05, 1.3793205e-07, 1.0, 7.0436954e-06, 0.011456132, 0.00051026879, 0.00076399726, 1.0, 1.0, 0.00067440601, 0.0001631389, 8.232716e-06, 1.0, 0.56276, 1.0], [1.0, 0.99985504, 0.033030141, 1.0, 5.2451054e-05, 1.0, 1.0, 1.0, 1.0, 0.0092287501, 2.6246784e-05, 0.00057937164, 3.7704685e-05, 0.0029114226, 1.0, 1.7207541e-06, 0.00014504181, 2.5431881e-08, 4.5921765e-06, 1.7454417e-08, 4.3881752e-08, 4.9859615e-08, 7.6701355e-08, 1.1386561e-07, 7.7139575e-08, 1.6809396e-07, 1.8448299e-07, 2.0047401e-07, 2.1260706e-07, 2.2022914e-07, 2.2514095e-07, 2.2708426e-07, 2.2673025e-07, 2.2594401e-07, 2.266663e-07, 2.3166254e-07, 2.4756005e-07, 2.9279593e-07, 0.0021795791, 1.0, 1.0, 9.0745743e-08, 1.0], [1.0, 0.99985504, 0.033030141, 1.0, 5.2451054e-05, 1.0, 1.0, 1.0, 1.0, 0.0092287501, 2.6246784e-05, 0.00057937164, 3.7704685e-05, 0.0029114226, 1.0, 1.7207541e-06, 0.00014504181, 2.5431881e-08, 4.5921765e-06, 1.7454417e-08, 4.3881752e-08, 4.9859615e-08, 7.6701355e-08, 1.1386561e-07, 7.7139575e-08, 1.6809396e-07, 1.8448299e-07, 2.0047401e-07, 2.1260706e-07, 2.2022914e-07, 2.2514095e-07, 2.2708426e-07, 2.2673025e-07, 2.2594401e-07, 2.266663e-07, 2.3166254e-07, 2.4756005e-07, 2.9279593e-07, 4.5257724e-07, 0.0057528131, 1.0, 1.0, 2.5252177e-05, 1.0], [1.0, 0.99985504, 0.033030141, 1.0, 5.2451054e-05, 1.0, 1.0, 1.0, 1.0, 0.0092287501, 2.6246784e-05, 0.00057937164, 3.7704685e-05, 0.0029114226, 1.0, 1.7207541e-06, 0.00014504181, 2.5431881e-08, 4.5921765e-06, 1.7454417e-08, 4.3881752e-08, 4.9859615e-08, 7.6701355e-08, 1.1386561e-07, 7.7139575e-08, 1.6809396e-07, 1.8448299e-07, 2.0047401e-07, 2.1260706e-07, 2.2022914e-07, 2.2514095e-07, 2.2708426e-07, 2.2673025e-07, 2.2594401e-07, 2.266663e-07, 2.3166254e-07, 2.4756005e-07, 2.9279593e-07, 4.5257724e-07, 0.0057528131, 1.0, 1.0, 0.93662071, 1.0]]
