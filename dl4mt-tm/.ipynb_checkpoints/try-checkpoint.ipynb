{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32,\n",
      " 'beamsize': 5,\n",
      " 'clip_c': 1.0,\n",
      " 'd_maxlen': 200,\n",
      " 'datasets': ['/root/workspace/TMNMT/.dataset/fren.bpe/train.fr.tok.bpe.shuf',\n",
      "              '/root/workspace/TMNMT/.dataset/fren.bpe/train.en.tok.bpe.shuf',\n",
      "              '/root/workspace/TMNMT/.dataset/fren.bpe/train.fr.tok.bpe.shuf',\n",
      "              '/root/workspace/TMNMT/.dataset/fren.bpe/train.en.tok.bpe.shuf'],\n",
      " 'decay_c': 0.0,\n",
      " 'decoder': 'gru_cond',\n",
      " 'dictionaries': ['/root/workspace/TMNMT/.dataset/fren.bpe/train.fr.tok.bpe.pkl',\n",
      "                  '/root/workspace/TMNMT/.dataset/fren.bpe/train.en.tok.bpe.pkl',\n",
      "                  '/root/workspace/TMNMT/.dataset/fren.bpe/train.fr.tok.bpe.pkl',\n",
      "                  '/root/workspace/TMNMT/.dataset/fren.bpe/train.en.tok.bpe.pkl'],\n",
      " 'dim': 1024,\n",
      " 'dim_word': 512,\n",
      " 'dispFreq': 10,\n",
      " 'encoder': 'gru',\n",
      " 'lrate': 2e-05,\n",
      " 'maxlen': 80,\n",
      " 'normalize': False,\n",
      " 'optimizer': 'adam',\n",
      " 'overwrite': False,\n",
      " 'patience': 10,\n",
      " 'reload_': True,\n",
      " 'sampleFreq': 100,\n",
      " 'saveFreq': 100,\n",
      " 'saveto': '/root/workspace/TMNMT/.model/tmv1_fren.bpe.npz',\n",
      " 'trans_from': '/root/workspace/TMNMT/.dataset/fren.bpe/devset.fr.tok.bpe',\n",
      " 'trans_ref': '/root/workspace/TMNMT/.dataset/fren/devset.en.tok',\n",
      " 'trans_to': '/root/workspace/TMNMT/.translate/baseline_fren.bpe.valid',\n",
      " 'use_dropout': False,\n",
      " 'validFreq': 100,\n",
      " 'valid_batch_size': 32,\n",
      " 'valid_datasets': ['/root/workspace/TMNMT/.dataset/fren.bpe/devset.fr.tok.bpe',\n",
      "                    '/root/workspace/TMNMT/.dataset/fren.bpe/devset.en.tok.bpe',\n",
      "                    '/root/workspace/TMNMT/.dataset/fren.bpe/devset.fr.tok.bpe',\n",
      "                    '/root/workspace/TMNMT/.dataset/fren.bpe/devset.en.tok.bpe'],\n",
      " 'voc_sizes': [20000, 20000, 20000, 20000]}\n",
      " Loading data\n",
      "Building model: E -> F & F -> E model\n"
     ]
    }
   ],
   "source": [
    "# %load train_nmt.py\n",
    "from nmt import *\n",
    "from pprint import pprint\n",
    "from setup import setup\n",
    "from data_iterator import TextIterator, prepare_data, prepare_cross\n",
    "\n",
    "model_options = setup('fren_bpe')\n",
    "pprint(model_options)\n",
    "\n",
    "# add random seed\n",
    "model_options['trng'] = RandomStreams(19920206)\n",
    "model_options['n_words_src'] = model_options['voc_sizes'][0]\n",
    "model_options['n_words'] = model_options['voc_sizes'][1]\n",
    "\n",
    "# load dictionaries and invert them\n",
    "worddicts   = [None] * len(model_options['dictionaries'])\n",
    "worddicts_r = [None] * len(model_options['dictionaries'])\n",
    "for ii, dd in enumerate(model_options['dictionaries']):\n",
    "    with open(dd, 'rb') as f:\n",
    "        worddicts[ii] = pkl.load(f)\n",
    "    worddicts_r[ii] = dict()\n",
    "    for kk, vv in worddicts[ii].iteritems():\n",
    "        worddicts_r[ii][vv] = kk\n",
    "\n",
    "# reload options\n",
    "if model_options['reload_'] and os.path.exists(model_options['saveto']):\n",
    "    print 'Reloading model options'\n",
    "    with open('%s.pkl' % saveto, 'rb') as f:\n",
    "        model_options = pkl.load(f)\n",
    "\n",
    "print 'Loading data'\n",
    "train = TextIterator(model_options['datasets'], model_options['dictionaries'], model_options['voc_sizes'], \n",
    "                     batch_size=model_options['batch_size'], maxlen=model_options['maxlen'])\n",
    "valid = TextIterator(model_options['valid_datasets'], model_options['dictionaries'], model_options['voc_sizes'], \n",
    "                     batch_size=model_options['batch_size'], maxlen=200)\n",
    "\n",
    "@Timeit\n",
    "def build_networks(options):\n",
    "    funcs = dict()\n",
    "\n",
    "    print 'Building model: E -> F & F -> E model'\n",
    "    params_ef = init_params(options, 'ef_')\n",
    "    params_fe = init_params(options, 'fe_')\n",
    "    print 'Done.'\n",
    "\n",
    "    # reload parameters\n",
    "    if options['reload_'] and os.path.exists(options['saveto']):\n",
    "        print 'Reloading model parameters'\n",
    "        params_ef = load_params(options['saveto'], params_ef)\n",
    "        params_fe = load_params(options['saveto'], params_fe)\n",
    "\n",
    "    tparams_ef = init_tparams(params_ef)\n",
    "    tparams_fe = init_tparams(params_fe)\n",
    "\n",
    "    # inputs of the model (x1, y1, x2, y2)\n",
    "    x1 = tensor.matrix('x1', dtype='int64')\n",
    "    x1_mask = tensor.matrix('x1_mask', dtype='float32')\n",
    "    y1 = tensor.matrix('y1', dtype='int64')\n",
    "    y1_mask = tensor.matrix('y1_mask', dtype='float32')\n",
    "    x2 = tensor.matrix('x2', dtype='int64')\n",
    "    x2_mask = tensor.matrix('x2_mask', dtype='float32')\n",
    "    y2 = tensor.matrix('y2', dtype='int64')\n",
    "    y2_mask = tensor.matrix('y2_mask', dtype='float32')\n",
    "\n",
    "    # TM reference index\n",
    "    tef12 = tensor.matrix('ef12', dtype='int64')\n",
    "    tef12_mask = tensor.matrix('ef12_mask', dtype='float32')\n",
    "    tef21 = tensor.matrix('ef21', dtype='int64')\n",
    "    tef21_mask = tensor.matrix('ef21_mask', dtype='float32')\n",
    "    tfe12 = tensor.matrix('fe12', dtype='int64')\n",
    "    tfe12_mask = tensor.matrix('fe12_mask', dtype='float32')\n",
    "    tfe21 = tensor.matrix('fe21', dtype='int64')\n",
    "    tfe21_mask = tensor.matrix('fe21_mask', dtype='float32')\n",
    "\n",
    "    print 'build forward-attention models (4 models simultaneously)'\n",
    "    ret_ef11 = build_model(tparams_ef, [x1, x1_mask, y1, y1_mask], options, 'ef_', False)  # E->F curr\n",
    "    ret_fe11 = build_model(tparams_fe, [y1, y1_mask, x1, x1_mask], options, 'fe_', False)  # F->E curr\n",
    "    ret_ef22 = build_model(tparams_ef, [x2, x2_mask, y2, y2_mask], options, 'ef_', False)  # E->F tm\n",
    "    ret_fe22 = build_model(tparams_fe, [y2, y2_mask, x2, x2_mask], options, 'fe_', False)  # F->E tm\n",
    "\n",
    "    print 'build cross-attention models'\n",
    "    ret_ef12 = build_attender(tparams_ef,\n",
    "                              [ret_ef11['prev_hids'], ret_ef11['prev_emb'], ret_ef22['ctx'], x2_mask],\n",
    "                              options, 'ef_')  # E->F curr\n",
    "    ret_ef21 = build_attender(tparams_ef,\n",
    "                              [ret_ef22['prev_hids'], ret_ef22['prev_emb'], ret_ef11['ctx'], x1_mask],\n",
    "                              options, 'ef_')  # E->F tm\n",
    "    ret_fe12 = build_attender(tparams_fe,\n",
    "                              [ret_fe11['prev_hids'], ret_fe11['prev_emb'], ret_fe22['ctx'], y2_mask],\n",
    "                              options, 'fe_')  # F->E curr\n",
    "    ret_fe21 = build_attender(tparams_fe,\n",
    "                              [ret_fe22['prev_hids'], ret_fe22['prev_emb'], ret_fe11['ctx'], y1_mask],\n",
    "                              options, 'fe_')  # F->E tm\n",
    "\n",
    "    print 'build attentions (forward, cross-propagation)'\n",
    "\n",
    "    def build_prop(atten_ef, atten_fe):\n",
    "        atten_ef = atten_ef.dimshuffle(1, 0, 2)\n",
    "        atten_fe = atten_fe.dimshuffle(1, 0, 2)\n",
    "        attention = tensor.batched_dot(atten_ef, atten_fe).dimshuffle(1, 0, 2)\n",
    "        return attention\n",
    "\n",
    "    att_ef12 = build_prop(ret_ef12['attention'], ret_fe22['attention'])\n",
    "    att_ef21 = build_prop(ret_ef21['attention'], ret_fe11['attention'])\n",
    "    att_fe12 = build_prop(ret_fe12['attention'], ret_ef22['attention'])\n",
    "    att_fe21 = build_prop(ret_fe21['attention'], ret_ef11['attention'])\n",
    "\n",
    "    print 'build loss function (w/o gate)'\n",
    "\n",
    "    # we first try the simplest version: use a natural attention-gate.\n",
    "    # TODO: make it as a Neural Gate\n",
    "    gate_ef1 = ret_ef11['att_sum'] / (ret_ef11['att_sum'] + ret_ef12['att_sum'])\n",
    "    gate_ef2 = ret_ef22['att_sum'] / (ret_ef22['att_sum'] + ret_ef21['att_sum'])\n",
    "    gate_fe1 = ret_fe11['att_sum'] / (ret_fe11['att_sum'] + ret_fe12['att_sum'])\n",
    "    gate_fe2 = ret_fe22['att_sum'] / (ret_fe22['att_sum'] + ret_fe21['att_sum'])\n",
    "\n",
    "    # get the loss function\n",
    "    def compute_prob(probs, y, y_mask):\n",
    "\n",
    "        # compute the loss for the vocabulary-selection side\n",
    "        y_flat  = y.flatten()\n",
    "        n_words = probs.shape[-1]\n",
    "        y_flat_idx = tensor.arange(y_flat.shape[0]) * n_words + y_flat\n",
    "        probw = probs.flatten()[y_flat_idx]\n",
    "        probw = probw.reshape([y.shape[0], y.shape[1]]) * y_mask\n",
    "        return probw\n",
    "\n",
    "    prob_ef11 = ret_ef11['probs']\n",
    "    prob_ef22 = ret_ef22['probs']\n",
    "    prob_fe11 = ret_fe11['probs']\n",
    "    prob_fe22 = ret_fe22['probs']\n",
    "\n",
    "    # get cost\n",
    "    cost_ef1 = (-tensor.log(compute_prob(prob_ef11, y1, y1_mask) * gate_ef1 +\n",
    "                            compute_prob(att_ef12, tef12, tef12_mask) * (1 - gate_ef1)\n",
    "                            + 1e-8) * (1 - (1 - y1_mask) * (1 - tef12_mask))).sum(0)\n",
    "    cost_ef2 = (-tensor.log(compute_prob(prob_ef22, y2, y2_mask) * gate_ef2 +\n",
    "                            compute_prob(att_ef21, tef21, tef21_mask) * (1 - gate_ef2)\n",
    "                            + 1e-8) * (1 - (1 - y2_mask) * (1 - tef21_mask))).sum(0)\n",
    "    cost_fe1 = (-tensor.log(compute_prob(prob_fe11, x1, x1_mask) * gate_fe1 +\n",
    "                            compute_prob(att_fe12, tfe12, tfe12_mask) * (1 - gate_fe1)\n",
    "                            + 1e-8) * (1 - (1 - x1_mask) * (1 - tfe12_mask))).sum(0)\n",
    "    cost_fe2 = (-tensor.log(compute_prob(prob_fe22, x2, x2_mask) * gate_fe2 +\n",
    "                            compute_prob(att_fe21, tfe21, tfe21_mask) * (1 - gate_fe2)\n",
    "                            + 1e-8) * (1 - (1 - x2_mask) * (1 - tfe21_mask))).sum(0)\n",
    "\n",
    "    cost = cost_ef1 + cost_ef2 + cost_fe1 + cost_fe2\n",
    "\n",
    "    # print 'Building sampler'\n",
    "    # f_init, f_next = build_sampler(tparams, options, trng, use_noise)\n",
    "\n",
    "    # before any regularizer\n",
    "    print 'Building Cost Function...',\n",
    "    inputs = [x1, x1_mask, y1, y1_mask, x2, x2_mask, y2, y2_mask,\n",
    "              tef12, tef12_mask, tef21, tef21_mask,\n",
    "              tfe12, tfe12_mask, tfe21, tfe21_mask]\n",
    "\n",
    "    # f_cost = theano.function(inputs, cost, profile=profile)\n",
    "    # print 'Done'\n",
    "\n",
    "    cost = cost.mean()\n",
    "\n",
    "    print 'Build Gradient (backward)...',\n",
    "\n",
    "    tparams = dict(tparams_ef.items() + tparams_fe.items())\n",
    "    grads   = clip(tensor.grad(cost, wrt=itemlist(tparams)), options['clip_c'])\n",
    "    print 'Done'\n",
    "\n",
    "    # compile the optimizer, the actual computational graph is compiled here\n",
    "    lr = tensor.scalar(name='lr')\n",
    "    print 'Building Optimizers...',\n",
    "    f_cost, f_update = eval(options['optimizer'])(lr, tparams, grads, inputs, cost)\n",
    "\n",
    "    funcs['cost']   = f_cost\n",
    "    funcs['update'] = f_update\n",
    "\n",
    "    print 'Done'\n",
    "    return funcs\n",
    "\n",
    "funcs = build_networks(model_options)\n",
    "\n",
    "print '..Upto here.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 530 530 530 530 \n",
      "(79, 32) (79, 32) (50, 32) (50, 32)\n",
      "cost="
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "One of the index value is out of bound. Error code: 65535.\\n\nApply node that caused the error: GpuAdvancedSubtensor1(GpuReshape{1}.0, Elemwise{Composite{((i0 * i1) + i2)}}[(0, 1)].0)\nToposort index: 4511\nInputs types: [CudaNdarrayType(float32, vector), TensorType(int64, vector)]\nInputs shapes: [(80000,), (1600,)]\nInputs strides: [(1,), (8,)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuReshape{2}(GpuAdvancedSubtensor1.0, MakeVector{dtype='int64'}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9edaf34ff3b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m             tx12, tx12_mask, tx21, tx21_mask]\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'cost='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cost'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'update'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'update'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    872\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: One of the index value is out of bound. Error code: 65535.\\n\nApply node that caused the error: GpuAdvancedSubtensor1(GpuReshape{1}.0, Elemwise{Composite{((i0 * i1) + i2)}}[(0, 1)].0)\nToposort index: 4511\nInputs types: [CudaNdarrayType(float32, vector), TensorType(int64, vector)]\nInputs shapes: [(80000,), (1600,)]\nInputs strides: [(1,), (8,)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuReshape{2}(GpuAdvancedSubtensor1.0, MakeVector{dtype='int64'}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "train.reset()\n",
    "lrate = model_options['lrate']\n",
    "for k, (sx1, sy1, sx2, sy2) in enumerate(train):\n",
    "    x1, x1_mask = prepare_data(sx1, model_options['maxlen'], model_options['voc_sizes'][0])\n",
    "    y1, y1_mask = prepare_data(sy1, model_options['maxlen'], model_options['voc_sizes'][1])\n",
    "    x2, x2_mask = prepare_data(sx2, model_options['maxlen'], model_options['voc_sizes'][2])\n",
    "    y2, y2_mask = prepare_data(sy2, model_options['maxlen'], model_options['voc_sizes'][3])\n",
    "    \n",
    "    print x1.shape, x2.shape, y1.shape, y2.shape\n",
    "    tx12, tx12_mask = prepare_cross(sx1, sx2, x1.shape[0])\n",
    "    tx21, tx21_mask = prepare_cross(sx2, sx1, x2.shape[0])\n",
    "    ty12, ty12_mask = prepare_cross(sy1, sy2, y1.shape[0])\n",
    "    ty21, ty21_mask = prepare_cross(sy1, sy2, y2.shape[0])\n",
    "    \n",
    "    inps = [x1, x1_mask, y1, y1_mask, \n",
    "            x2, x2_mask, y2, y2_mask,\n",
    "            ty12, ty12_mask, ty21, ty21_mask,\n",
    "            tx12, tx12_mask, tx21, tx21_mask]\n",
    "    \n",
    "    print 'cost=', funcs['cost'](*inps)\n",
    "    print 'update', funcs['update'](lrate)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16832   197   218    57  1709  1972    14    47     3   414    68     3\n",
      "    47    40   418 17854   147 11917    20   294    20   290    95    40\n",
      "   143     3  5490]\n"
     ]
    }
   ],
   "source": [
    "print x2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "a = [23, 1,2,32,23, 23,4]\n",
    "b = [23, 2,10,23]\n",
    "idx = [[(i, abs(i-j)) for i, x in enumerate(a) if x == y] for j, y in enumerate(b)]\n",
    "print sorted(idx[3], key=lambda a:a[1])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
